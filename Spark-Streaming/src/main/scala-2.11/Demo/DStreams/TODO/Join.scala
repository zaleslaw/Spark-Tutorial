package Demo.DStreams.TODO

/*

val dataset = sparkContext.hadoopFile(“file”)

kafkaDStream.transform { batchRDD =>
  batchRDD.join(dataset).filter(...)
}

 */
object Join {
  def main(args: Array[String]): Unit = {

  }
}
